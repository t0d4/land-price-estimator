{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_ROOT = \"./dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import os\n",
    "import random\n",
    "\n",
    "from typing import Tuple, Union\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as nnF\n",
    "import torchvision.transforms.functional as trF\n",
    "from torch import nn, Tensor\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.io import read_image, ImageReadMode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we begin, let's see how the distribution of land price looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_all = pd.read_csv(\n",
    "    os.path.join(DATASET_ROOT, \"data_catalogue.csv\"),\n",
    "    index_col=False\n",
    ")\n",
    "# df_all[\"landprice\"].hist(bins=10)\n",
    "df_all[\"log_landprice\"] = np.log10(df_all[\"landprice\"])\n",
    "df_all[\"log_landprice\"].hist(bins=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Only once] Split into train, val, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_RATE = 0.8\n",
    "VAL_RATE = 0.1\n",
    "TEST_RATE = 0.1\n",
    "assert( TRAIN_RATE + VAL_RATE + TEST_RATE == 1.0 )\n",
    "\n",
    "df = pd.read_csv(\n",
    "    os.path.join(DATASET_ROOT, \"data_catalogue.csv\"),\n",
    "    index_col=False\n",
    ")\n",
    "data_count = len(df)\n",
    "\n",
    "shuffled_indices = list(range(data_count))\n",
    "random.shuffle(shuffled_indices)\n",
    "\n",
    "train_df = df.iloc[\n",
    "    shuffled_indices[:int(data_count*TRAIN_RATE)], :\n",
    "]\n",
    "val_df = df.iloc[\n",
    "    shuffled_indices[int(data_count*TRAIN_RATE):int(data_count*(TRAIN_RATE+VAL_RATE))] , :\n",
    "]\n",
    "test_df = df.iloc[\n",
    "    shuffled_indices[int(data_count*(TRAIN_RATE+VAL_RATE)):], :\n",
    "]\n",
    "\n",
    "train_df.to_csv(\n",
    "    os.path.join(DATASET_ROOT,\"train_data_catalogue.csv\"),\n",
    "    index=False\n",
    ")\n",
    "val_df.to_csv(\n",
    "    os.path.join(DATASET_ROOT,\"val_data_catalogue.csv\"),\n",
    "    index=False\n",
    ")\n",
    "test_df.to_csv(\n",
    "    os.path.join(DATASET_ROOT,\"test_data_catalogue.csv\"),\n",
    "    index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Dataset and DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LandPriceDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dataset_root_dir_path: str,\n",
    "        catalogue_csv_name: str,\n",
    "        target_img_size: Union[Tuple[int, int], None] = None,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        df = pd.read_csv(\n",
    "            os.path.join(dataset_root_dir_path, catalogue_csv_name),\n",
    "            index_col=False\n",
    "        )\n",
    "        self.img_paths = [\n",
    "            os.path.join(dataset_root_dir_path, \"images\", img_filename)\n",
    "            for img_filename in df[\"img_filename\"].to_list()\n",
    "        ]\n",
    "        self.segmap_paths = [\n",
    "            os.path.join(dataset_root_dir_path, \"masked_images\", mask_filename)\n",
    "            for mask_filename in df[\"mask_filename\"].to_list()\n",
    "        ]\n",
    "        self.landprices = df[\"landprice\"].to_list()\n",
    "        self.target_img_size = target_img_size\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.img_paths)\n",
    "\n",
    "    def __getitem__(self, index: int) -> Tuple[str, Tensor, Tensor, Tensor]:\n",
    "        img_path = self.img_paths[index]\n",
    "        image = read_image(\n",
    "            path=img_path,\n",
    "            mode=ImageReadMode.RGB\n",
    "        )\n",
    "        # extract 000001 from satellite000001.png\n",
    "        image_id = os.path.basename(img_path)[9:15]\n",
    "\n",
    "        segmap_path = self.segmap_paths[index]\n",
    "        segmap = read_image(\n",
    "            path=segmap_path,\n",
    "            mode=ImageReadMode.GRAY\n",
    "        )\n",
    "\n",
    "        landprice = self.landprices[index]\n",
    "        landprice = torch.tensor(landprice)\n",
    "\n",
    "        if self.target_img_size:\n",
    "            image = trF.resize(\n",
    "                img=image,\n",
    "                size=self.target_img_size,\n",
    "            )\n",
    "            segmap = nnF.interpolate(\n",
    "                input=segmap.unsqueeze(0),\n",
    "                size=self.target_img_size,\n",
    "                mode=\"nearest\",\n",
    "            )\n",
    "\n",
    "        # one-hot encoding for segmap\n",
    "        SEGMAP_CLASS_NUM = 8\n",
    "        segmap = nnF.one_hot(segmap.long(), SEGMAP_CLASS_NUM).transpose(1, 4).squeeze()\n",
    "        # segmap is like torch.Size([SEGMAP_CLASS_NUM, SEGMAP_H, SEGMAP_W])\n",
    "\n",
    "        return image_id, image.float(), segmap.float(), landprice.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_IMAGE_SIZE = 480\n",
    "\n",
    "train_ds = LandPriceDataset(\n",
    "    dataset_root_dir_path=DATASET_ROOT,\n",
    "    catalogue_csv_name=\"train_data_catalogue.csv\",\n",
    "    target_img_size=(TARGET_IMAGE_SIZE, TARGET_IMAGE_SIZE)\n",
    ")\n",
    "val_ds = LandPriceDataset(\n",
    "    dataset_root_dir_path=DATASET_ROOT,\n",
    "    catalogue_csv_name=\"val_data_catalogue.csv\",\n",
    "    target_img_size=(TARGET_IMAGE_SIZE, TARGET_IMAGE_SIZE),\n",
    ")\n",
    "test_ds = LandPriceDataset(\n",
    "    dataset_root_dir_path=DATASET_ROOT,\n",
    "    catalogue_csv_name=\"test_data_catalogue.csv\",\n",
    "    target_img_size=(TARGET_IMAGE_SIZE, TARGET_IMAGE_SIZE),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import efficientnet_v2_m, EfficientNet_V2_M_Weights\n",
    "\n",
    "class FeatureMapCompresser(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.dropout = nn.Dropout(p=0.3)\n",
    "        # (height_of_feature_map)x(width_of_feature_map)x(num_filter_for_each_channel)\n",
    "        self.feat_wise_fc_to_128 = nn.Linear(in_features=29*29*2, out_features=128)\n",
    "        self.feat_wise_fc_last = nn.Linear(in_features=128, out_features=32)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.feat_wise_fc_to_128(x)\n",
    "        x = self.feat_wise_fc_last(x)\n",
    "        return x\n",
    "\n",
    "class EfficientNetBasedFeatureExtractor(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        whole_effnet = efficientnet_v2_m(\n",
    "            weights=EfficientNet_V2_M_Weights.IMAGENET1K_V1\n",
    "        )\n",
    "        # omit the last classification layer\n",
    "        self.effnet_without_classifier = nn.Sequential(\n",
    "            whole_effnet.features,\n",
    "            whole_effnet.avgpool,\n",
    "        )\n",
    "        self.fc_to_512 = nn.Linear(in_features=1280, out_features=512)\n",
    "        self.fc_to_256 = nn.Linear(in_features=512, out_features=256)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.effnet_without_classifier(x)  # size of x == torch.Size([BATCH, 1280, 1, 1])\n",
    "        x = torch.squeeze(x)\n",
    "        x = self.fc_to_512(x)\n",
    "        x = self.fc_to_256(x)\n",
    "        return x\n",
    "\n",
    "class LandNet(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.effnet_feat_extractor = EfficientNetBasedFeatureExtractor()\n",
    "        self.conv_feat_extractor = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=6, # number of meaningful class in segmentation maps\n",
    "                out_channels=12,\n",
    "                kernel_size=4,\n",
    "                groups=6  # MUST be the same as `in_channels`. This works as depth-wise convolution\n",
    "                # `out_channels`/`in_channels` (= 2) dedicated filters are applied to each channel in the input\n",
    "            ),\n",
    "            nn.MaxPool2d(kernel_size=16),  # each side of feature map becomes 1/16 the length of previous one\n",
    "            # # this another convolution seems to be unnecessary\n",
    "            # nn.Conv2d(\n",
    "            #     in_channels=18,\n",
    "            #     out_channels=36,\n",
    "            #     kernel_size=2,\n",
    "            #     groups=3,\n",
    "            # ),\n",
    "            # nn.MaxPool2d(kernel_size=4),\n",
    "        )\n",
    "        self.feat_compresser_for_build = FeatureMapCompresser()\n",
    "        self.feat_compresser_for_road = FeatureMapCompresser()\n",
    "        self.feat_compresser_for_water = FeatureMapCompresser()\n",
    "        self.feat_compresser_for_barren = FeatureMapCompresser()\n",
    "        self.feat_compresser_for_forest = FeatureMapCompresser()\n",
    "        self.feat_compresser_for_agri = FeatureMapCompresser()\n",
    "\n",
    "        self.trailing_fc_to_256 = nn.Linear(in_features=256+32*6, out_features=256)\n",
    "        self.trailing_fc_to_64 = nn.Linear(in_features=256, out_features=64)\n",
    "        self.last_fc = nn.Linear(in_features=64, out_features=1)\n",
    "        self.dropout = nn.Dropout(p=0.3)\n",
    "\n",
    "    def forward(self, image, segmap):\n",
    "        feat_image = self.effnet_feat_extractor(image)\n",
    "\n",
    "        y = self.conv_feat_extractor(segmap)\n",
    "        feat_build = self.feat_compresser_for_build(y[:, :2, ...])\n",
    "        feat_road = self.feat_compresser_for_road(y[:, 2:4, ...])\n",
    "        feat_water = self.feat_compresser_for_water(y[:, 4:6, ...])\n",
    "        feat_barren = self.feat_compresser_for_barren(y[:, 6:8, ...])\n",
    "        feat_forest = self.feat_compresser_for_forest(y[:, 8:10, ...])\n",
    "        feat_agri = self.feat_compresser_for_agri(y[:, 10:12, ...])\n",
    "\n",
    "        feat_concat = torch.cat(\n",
    "            tensors=[feat_image, feat_build, feat_road, feat_water, feat_barren, feat_forest, feat_agri],\n",
    "            dim=1\n",
    "        )\n",
    "        overall_feat = self.trailing_fc_to_256(feat_concat)\n",
    "        overall_feat = self.dropout(overall_feat)\n",
    "        overall_feat = self.trailing_fc_to_64(overall_feat)\n",
    "        pred_value = self.last_fc(overall_feat)\n",
    "\n",
    "        return pred_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the number of parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of parameters:  55094529\n"
     ]
    }
   ],
   "source": [
    "landnet = LandNet().to(device)\n",
    "params = 0\n",
    "for p in landnet.parameters():\n",
    "    if p.requires_grad:\n",
    "        params += p.numel()\n",
    "print(\"number of parameters: \", params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test if the shape is correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dummy_image = torch.randn(2, 3, 480, 480)\n",
    "# dummy_segmap = torch.randn(2, 6, 480, 480)\n",
    "# landnet(dummy_image, dummy_segmap)\n",
    "\n",
    "# # features only: torch.Size([2, 1280, 15, 15])\n",
    "# # features+avgpool: torch.Size([2, 1280, 1, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-17 21:32:28.511211: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from textwrap import dedent\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# Based on the observation at the beginning of this notebook,\n",
    "# let's employ Rooted Mean Squared Logarithmic Error\n",
    "# https://atmarkit.itmedia.co.jp/ait/articles/2106/02/news021.html\n",
    "class RMSLELoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.mse = nn.MSELoss()\n",
    "        self.constant = 10\n",
    "\n",
    "    def forward(self, pred, actual):\n",
    "        return torch.sqrt(self.mse(torch.log(pred + self.constant), torch.log(actual + self.constant)))\n",
    "\n",
    "loss_func = RMSLELoss()\n",
    "optimizer = torch.optim.AdamW(\n",
    "    params=landnet.parameters(),\n",
    "    weight_decay=1e-4\n",
    ")\n",
    "\n",
    "def train(\n",
    "    dataloader: DataLoader,\n",
    "    model: LandNet,\n",
    "    loss_func: RMSLELoss,\n",
    "    optimizer: torch.optim.AdamW,\n",
    "    current_epoch: int,\n",
    "    writer: SummaryWriter,\n",
    "):\n",
    "    whole_size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    mean_loss_in_epoch = .0\n",
    "    mean_deviation_in_epoch = .0\n",
    "    for batch_pos, (image_id, image, segmap, landprice) in enumerate(dataloader):\n",
    "\n",
    "        image, landprice = image.to(device), landprice.to(device)\n",
    "        # omit segmaps for Ignore (0), Background (1)\n",
    "        segmap = segmap[:, 2:, ...]\n",
    "        segmap = segmap.to(device)\n",
    "\n",
    "        # compute the prediction\n",
    "        pred = model(image, segmap)\n",
    "        loss = loss_func(pred, landprice)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # update mean loss\n",
    "        loss = loss.item()\n",
    "        mean_loss_in_epoch = (batch_pos*mean_loss_in_epoch + loss)/(batch_pos+1)\n",
    "        # update mean deviation rate\n",
    "        deviations = torch.abs(pred - landprice) / landprice\n",
    "        mean_deviation_in_batch = deviations.mean().item()\n",
    "        mean_deviation_in_epoch = (batch_pos*mean_deviation_in_epoch + mean_deviation_in_batch)/(batch_pos+1)\n",
    "\n",
    "        if batch_pos % 100 == 0:\n",
    "            current_pos = batch_pos*len(image)\n",
    "            print(dedent(\n",
    "                f\"\"\"[{current_pos:>5d}/{whole_size:>5d}]\\n\\\n",
    "                loss: {loss:>7f}\\n\\\n",
    "                current_mean_loss_in_epoch: {mean_loss_in_epoch:>7f}\\n\\\n",
    "                current_mean_deviation_rate_in_epoch: {mean_deviation_in_epoch:>7f}\"\"\"))\n",
    "\n",
    "    writer.add_scalar(\n",
    "        tag=\"loss/train\",\n",
    "        scalar_value=mean_loss_in_epoch,\n",
    "        global_step=current_epoch,\n",
    "    )\n",
    "    writer.add_scalar(\n",
    "        tag=\"deviation_rate/train\",\n",
    "        scalar_value=mean_deviation_in_epoch,\n",
    "        global_step=current_epoch,\n",
    "    )\n",
    "    writer.flush()\n",
    "\n",
    "def validate(\n",
    "    dataloader: DataLoader,\n",
    "    model: LandNet,\n",
    "    loss_func: RMSLELoss,\n",
    "    current_epoch: int,\n",
    "    writer: Union[SummaryWriter, None] = None,\n",
    "    summary_csv_path: Union[str, None] = None,\n",
    "):\n",
    "    whole_size = len(dataloader.dataset)\n",
    "    model.eval()\n",
    "    mean_loss_in_epoch = .0\n",
    "    mean_deviation_in_epoch = .0\n",
    "    image_id_log = []\n",
    "    deviation_log = []\n",
    "    pred_log = []\n",
    "    landprice_log = []\n",
    "    with torch.no_grad():\n",
    "        for batch_pos, (image_id, image, segmap, landprice) in enumerate(dataloader):\n",
    "\n",
    "            image, landprice = image.to(device), landprice.to(device)\n",
    "            segmap = segmap[:, 2:, ...]\n",
    "            segmap = segmap.to(device)\n",
    "\n",
    "            # compute the prediction\n",
    "            pred = model(image, segmap)\n",
    "            loss = loss_func(pred, landprice)\n",
    "\n",
    "            # update mean loss\n",
    "            loss = loss.item()\n",
    "            mean_loss_in_epoch = (batch_pos*mean_loss_in_epoch + loss)/(batch_pos+1)\n",
    "            # update mean deviation rate\n",
    "            deviations = torch.abs(pred.squeeze() - landprice) / landprice\n",
    "            mean_deviation_in_batch = deviations.mean().item()\n",
    "            mean_deviation_in_epoch = (batch_pos*mean_deviation_in_epoch + mean_deviation_in_batch)/(batch_pos+1)\n",
    "\n",
    "            if summary_csv_path:\n",
    "                image_id_log += image_id\n",
    "                pred_log += pred.squeeze().cpu().tolist()\n",
    "                landprice_log += landprice.cpu().tolist()\n",
    "                deviation_log += deviations.cpu().tolist()\n",
    "\n",
    "            if batch_pos % 100 == 0:\n",
    "                current_pos = batch_pos*len(image)\n",
    "                print(dedent(\n",
    "                    f\"[{current_pos:>5d}/{whole_size:>5d}]\\n\\\n",
    "                    loss: {loss:>7f}\\n\\\n",
    "                    current_mean_loss_in_epoch: {mean_loss_in_epoch:>7f}\\n\\\n",
    "                    current_mean_deviation_rate_in_epoch: {mean_deviation_in_epoch:>7f}\"))\n",
    "\n",
    "    if summary_csv_path:\n",
    "        df = pd.DataFrame(\n",
    "            data={\n",
    "                \"image_id\": image_id_log,\n",
    "                \"prediction\": pred_log,\n",
    "                \"true_landprice\": landprice_log,\n",
    "                \"deviation\": deviation_log,\n",
    "            }\n",
    "        )\n",
    "        df.to_csv(summary_csv_path, index=False)\n",
    "\n",
    "    if writer:\n",
    "        writer.add_scalar(\n",
    "            tag=\"loss/val\",\n",
    "            scalar_value=mean_loss_in_epoch,\n",
    "            global_step=current_epoch,\n",
    "        )\n",
    "        writer.add_scalar(\n",
    "            tag=\"deviation_rate/val\",\n",
    "            scalar_value=mean_deviation_in_epoch,\n",
    "            global_step=current_epoch,\n",
    "        )\n",
    "        writer.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 5\n",
    "train_dl = DataLoader(dataset=train_ds, batch_size=BATCH_SIZE)\n",
    "val_dl = DataLoader(dataset=val_ds, batch_size=BATCH_SIZE)\n",
    "test_dl = DataLoader(dataset=test_ds, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execute training!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/toda/.venv/ml/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/home/toda/.venv/ml/lib/python3.8/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([5, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    0/20794]\n",
      "                loss: 9.791926\n",
      "                current_mean_loss_in_epoch: 9.791926\n",
      "                current_mean_deviation_rate_in_epoch: 1.000001\n",
      "[  500/20794]\n",
      "                loss: 1.405784\n",
      "                current_mean_loss_in_epoch: 1.985874\n",
      "                current_mean_deviation_rate_in_epoch: 1.724654\n",
      "[ 1000/20794]\n",
      "                loss: 1.199694\n",
      "                current_mean_loss_in_epoch: 1.663408\n",
      "                current_mean_deviation_rate_in_epoch: 1.829442\n",
      "[ 1500/20794]\n",
      "                loss: 0.931054\n",
      "                current_mean_loss_in_epoch: 1.496973\n",
      "                current_mean_deviation_rate_in_epoch: 1.715058\n",
      "[ 2000/20794]\n",
      "                loss: 0.422878\n",
      "                current_mean_loss_in_epoch: 1.405441\n",
      "                current_mean_deviation_rate_in_epoch: 1.675864\n",
      "[ 2500/20794]\n",
      "                loss: 1.757351\n",
      "                current_mean_loss_in_epoch: 1.373535\n",
      "                current_mean_deviation_rate_in_epoch: 1.720861\n",
      "[ 3000/20794]\n",
      "                loss: 1.424574\n",
      "                current_mean_loss_in_epoch: 1.343322\n",
      "                current_mean_deviation_rate_in_epoch: 1.692009\n",
      "[ 3500/20794]\n",
      "                loss: 0.701864\n",
      "                current_mean_loss_in_epoch: 1.323536\n",
      "                current_mean_deviation_rate_in_epoch: 1.663449\n",
      "[ 4000/20794]\n",
      "                loss: 1.319504\n",
      "                current_mean_loss_in_epoch: 1.300442\n",
      "                current_mean_deviation_rate_in_epoch: 1.641976\n",
      "[ 4500/20794]\n",
      "                loss: 0.973477\n",
      "                current_mean_loss_in_epoch: 1.288179\n",
      "                current_mean_deviation_rate_in_epoch: 1.610665\n",
      "[ 5000/20794]\n",
      "                loss: 1.162308\n",
      "                current_mean_loss_in_epoch: 1.277048\n",
      "                current_mean_deviation_rate_in_epoch: 1.617819\n",
      "[ 5500/20794]\n",
      "                loss: 1.191898\n",
      "                current_mean_loss_in_epoch: 1.272997\n",
      "                current_mean_deviation_rate_in_epoch: 1.624732\n",
      "[ 6000/20794]\n",
      "                loss: 1.332834\n",
      "                current_mean_loss_in_epoch: 1.263870\n",
      "                current_mean_deviation_rate_in_epoch: 1.621358\n",
      "[ 6500/20794]\n",
      "                loss: 0.987810\n",
      "                current_mean_loss_in_epoch: 1.257562\n",
      "                current_mean_deviation_rate_in_epoch: 1.609813\n",
      "[ 7000/20794]\n",
      "                loss: 1.349535\n",
      "                current_mean_loss_in_epoch: 1.252004\n",
      "                current_mean_deviation_rate_in_epoch: 1.596778\n",
      "[ 7500/20794]\n",
      "                loss: 0.492188\n",
      "                current_mean_loss_in_epoch: 1.247243\n",
      "                current_mean_deviation_rate_in_epoch: 1.596124\n",
      "[ 8000/20794]\n",
      "                loss: 1.233981\n",
      "                current_mean_loss_in_epoch: 1.245666\n",
      "                current_mean_deviation_rate_in_epoch: 1.592785\n",
      "[ 8500/20794]\n",
      "                loss: 0.872958\n",
      "                current_mean_loss_in_epoch: 1.242028\n",
      "                current_mean_deviation_rate_in_epoch: 1.593795\n",
      "[ 9000/20794]\n",
      "                loss: 2.362652\n",
      "                current_mean_loss_in_epoch: 1.240458\n",
      "                current_mean_deviation_rate_in_epoch: 1.590388\n",
      "[ 9500/20794]\n",
      "                loss: 1.586702\n",
      "                current_mean_loss_in_epoch: 1.238164\n",
      "                current_mean_deviation_rate_in_epoch: 1.589680\n",
      "[10000/20794]\n",
      "                loss: 0.870181\n",
      "                current_mean_loss_in_epoch: 1.235659\n",
      "                current_mean_deviation_rate_in_epoch: 1.596487\n",
      "[10500/20794]\n",
      "                loss: 1.043162\n",
      "                current_mean_loss_in_epoch: 1.230213\n",
      "                current_mean_deviation_rate_in_epoch: 1.577326\n",
      "[11000/20794]\n",
      "                loss: 0.832784\n",
      "                current_mean_loss_in_epoch: 1.232989\n",
      "                current_mean_deviation_rate_in_epoch: 1.593366\n",
      "[11500/20794]\n",
      "                loss: 2.229531\n",
      "                current_mean_loss_in_epoch: 1.234033\n",
      "                current_mean_deviation_rate_in_epoch: 1.591339\n",
      "[12000/20794]\n",
      "                loss: 1.053513\n",
      "                current_mean_loss_in_epoch: 1.230807\n",
      "                current_mean_deviation_rate_in_epoch: 1.583683\n",
      "[12500/20794]\n",
      "                loss: 1.934986\n",
      "                current_mean_loss_in_epoch: 1.229906\n",
      "                current_mean_deviation_rate_in_epoch: 1.586084\n",
      "[13000/20794]\n",
      "                loss: 1.205902\n",
      "                current_mean_loss_in_epoch: 1.227632\n",
      "                current_mean_deviation_rate_in_epoch: 1.575871\n",
      "[13500/20794]\n",
      "                loss: 1.231584\n",
      "                current_mean_loss_in_epoch: 1.226226\n",
      "                current_mean_deviation_rate_in_epoch: 1.577896\n",
      "[14000/20794]\n",
      "                loss: 0.768529\n",
      "                current_mean_loss_in_epoch: 1.225833\n",
      "                current_mean_deviation_rate_in_epoch: 1.573556\n",
      "[14500/20794]\n",
      "                loss: 1.068410\n",
      "                current_mean_loss_in_epoch: 1.224513\n",
      "                current_mean_deviation_rate_in_epoch: 1.564861\n",
      "[15000/20794]\n",
      "                loss: 1.217110\n",
      "                current_mean_loss_in_epoch: 1.222162\n",
      "                current_mean_deviation_rate_in_epoch: 1.557739\n",
      "[15500/20794]\n",
      "                loss: 1.569048\n",
      "                current_mean_loss_in_epoch: 1.222933\n",
      "                current_mean_deviation_rate_in_epoch: 1.557016\n",
      "[16000/20794]\n",
      "                loss: 1.491269\n",
      "                current_mean_loss_in_epoch: 1.221211\n",
      "                current_mean_deviation_rate_in_epoch: 1.555560\n",
      "[16500/20794]\n",
      "                loss: 0.699476\n",
      "                current_mean_loss_in_epoch: 1.219716\n",
      "                current_mean_deviation_rate_in_epoch: 1.552505\n",
      "[17000/20794]\n",
      "                loss: 1.087344\n",
      "                current_mean_loss_in_epoch: 1.217079\n",
      "                current_mean_deviation_rate_in_epoch: 1.544615\n",
      "[17500/20794]\n",
      "                loss: 0.713952\n",
      "                current_mean_loss_in_epoch: 1.216197\n",
      "                current_mean_deviation_rate_in_epoch: 1.552963\n",
      "[18000/20794]\n",
      "                loss: 1.221443\n",
      "                current_mean_loss_in_epoch: 1.214859\n",
      "                current_mean_deviation_rate_in_epoch: 1.553405\n",
      "[18500/20794]\n",
      "                loss: 1.131134\n",
      "                current_mean_loss_in_epoch: 1.210592\n",
      "                current_mean_deviation_rate_in_epoch: 1.546778\n",
      "[19000/20794]\n",
      "                loss: 1.593325\n",
      "                current_mean_loss_in_epoch: 1.209006\n",
      "                current_mean_deviation_rate_in_epoch: 1.541058\n",
      "[19500/20794]\n",
      "                loss: 0.785106\n",
      "                current_mean_loss_in_epoch: 1.208159\n",
      "                current_mean_deviation_rate_in_epoch: 1.537803\n",
      "[20000/20794]\n",
      "                loss: 1.801328\n",
      "                current_mean_loss_in_epoch: 1.207394\n",
      "                current_mean_deviation_rate_in_epoch: 1.535212\n",
      "[20500/20794]\n",
      "                loss: 0.293832\n",
      "                current_mean_loss_in_epoch: 1.207752\n",
      "                current_mean_deviation_rate_in_epoch: 1.540328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/toda/.venv/ml/lib/python3.8/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([4])) that is different to the input size (torch.Size([4, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    0/ 2599]\n",
      "                    loss: 1.136313\n",
      "                    current_mean_loss_in_epoch: 1.136313\n",
      "                    current_mean_deviation_rate_in_epoch: 1.048621\n",
      "[  500/ 2599]\n",
      "                    loss: 1.332837\n",
      "                    current_mean_loss_in_epoch: 1.149489\n",
      "                    current_mean_deviation_rate_in_epoch: 1.516117\n",
      "[ 1000/ 2599]\n",
      "                    loss: 0.649741\n",
      "                    current_mean_loss_in_epoch: 1.153048\n",
      "                    current_mean_deviation_rate_in_epoch: 1.496893\n",
      "[ 1500/ 2599]\n",
      "                    loss: 0.991934\n",
      "                    current_mean_loss_in_epoch: 1.163238\n",
      "                    current_mean_deviation_rate_in_epoch: 1.587317\n",
      "[ 2000/ 2599]\n",
      "                    loss: 0.774244\n",
      "                    current_mean_loss_in_epoch: 1.157710\n",
      "                    current_mean_deviation_rate_in_epoch: 1.613466\n",
      "[ 2500/ 2599]\n",
      "                    loss: 1.115322\n",
      "                    current_mean_loss_in_epoch: 1.157369\n",
      "                    current_mean_deviation_rate_in_epoch: 1.575845\n",
      "Epoch 1\n",
      "---------------------------------------\n",
      "[    0/20794]\n",
      "                loss: 1.270039\n",
      "                current_mean_loss_in_epoch: 1.270039\n",
      "                current_mean_deviation_rate_in_epoch: 0.696048\n",
      "[  500/20794]\n",
      "                loss: 1.473896\n",
      "                current_mean_loss_in_epoch: 1.209618\n",
      "                current_mean_deviation_rate_in_epoch: 1.734864\n",
      "[ 1000/20794]\n",
      "                loss: 1.124363\n",
      "                current_mean_loss_in_epoch: 1.260861\n",
      "                current_mean_deviation_rate_in_epoch: 1.782300\n",
      "[ 1500/20794]\n",
      "                loss: 0.852531\n",
      "                current_mean_loss_in_epoch: 1.223682\n",
      "                current_mean_deviation_rate_in_epoch: 1.678165\n",
      "[ 2000/20794]\n",
      "                loss: 0.448443\n",
      "                current_mean_loss_in_epoch: 1.199105\n",
      "                current_mean_deviation_rate_in_epoch: 1.639800\n",
      "[ 2500/20794]\n",
      "                loss: 1.758088\n",
      "                current_mean_loss_in_epoch: 1.207422\n",
      "                current_mean_deviation_rate_in_epoch: 1.681383\n",
      "[ 3000/20794]\n",
      "                loss: 1.325438\n",
      "                current_mean_loss_in_epoch: 1.203207\n",
      "                current_mean_deviation_rate_in_epoch: 1.657061\n",
      "[ 3500/20794]\n",
      "                loss: 0.705955\n",
      "                current_mean_loss_in_epoch: 1.202091\n",
      "                current_mean_deviation_rate_in_epoch: 1.626735\n",
      "[ 4000/20794]\n",
      "                loss: 1.305650\n",
      "                current_mean_loss_in_epoch: 1.193446\n",
      "                current_mean_deviation_rate_in_epoch: 1.606394\n",
      "[ 4500/20794]\n",
      "                loss: 0.976506\n",
      "                current_mean_loss_in_epoch: 1.192244\n",
      "                current_mean_deviation_rate_in_epoch: 1.575016\n",
      "[ 5000/20794]\n",
      "                loss: 1.119667\n",
      "                current_mean_loss_in_epoch: 1.190244\n",
      "                current_mean_deviation_rate_in_epoch: 1.585153\n",
      "[ 5500/20794]\n",
      "                loss: 1.134973\n",
      "                current_mean_loss_in_epoch: 1.193458\n",
      "                current_mean_deviation_rate_in_epoch: 1.594192\n",
      "[ 6000/20794]\n",
      "                loss: 1.217649\n",
      "                current_mean_loss_in_epoch: 1.190518\n",
      "                current_mean_deviation_rate_in_epoch: 1.587374\n",
      "[ 6500/20794]\n",
      "                loss: 1.008841\n",
      "                current_mean_loss_in_epoch: 1.189632\n",
      "                current_mean_deviation_rate_in_epoch: 1.577696\n",
      "[ 7000/20794]\n",
      "                loss: 1.335938\n",
      "                current_mean_loss_in_epoch: 1.188249\n",
      "                current_mean_deviation_rate_in_epoch: 1.565675\n",
      "[ 7500/20794]\n",
      "                loss: 0.570518\n",
      "                current_mean_loss_in_epoch: 1.187333\n",
      "                current_mean_deviation_rate_in_epoch: 1.565637\n",
      "[ 8000/20794]\n",
      "                loss: 1.239056\n",
      "                current_mean_loss_in_epoch: 1.189286\n",
      "                current_mean_deviation_rate_in_epoch: 1.563890\n",
      "[ 8500/20794]\n",
      "                loss: 0.936984\n",
      "                current_mean_loss_in_epoch: 1.188351\n",
      "                current_mean_deviation_rate_in_epoch: 1.566642\n",
      "[ 9000/20794]\n",
      "                loss: 2.349834\n",
      "                current_mean_loss_in_epoch: 1.188897\n",
      "                current_mean_deviation_rate_in_epoch: 1.562266\n",
      "[ 9500/20794]\n",
      "                loss: 1.537410\n",
      "                current_mean_loss_in_epoch: 1.188994\n",
      "                current_mean_deviation_rate_in_epoch: 1.563666\n",
      "[10000/20794]\n",
      "                loss: 0.841263\n",
      "                current_mean_loss_in_epoch: 1.188997\n",
      "                current_mean_deviation_rate_in_epoch: 1.570743\n",
      "[10500/20794]\n",
      "                loss: 1.006902\n",
      "                current_mean_loss_in_epoch: 1.185443\n",
      "                current_mean_deviation_rate_in_epoch: 1.552013\n",
      "[11000/20794]\n",
      "                loss: 0.816027\n",
      "                current_mean_loss_in_epoch: 1.189467\n",
      "                current_mean_deviation_rate_in_epoch: 1.566249\n",
      "[11500/20794]\n",
      "                loss: 2.271173\n",
      "                current_mean_loss_in_epoch: 1.191984\n",
      "                current_mean_deviation_rate_in_epoch: 1.564351\n",
      "[12000/20794]\n",
      "                loss: 1.048489\n",
      "                current_mean_loss_in_epoch: 1.190294\n",
      "                current_mean_deviation_rate_in_epoch: 1.557122\n",
      "[12500/20794]\n",
      "                loss: 1.940598\n",
      "                current_mean_loss_in_epoch: 1.190622\n",
      "                current_mean_deviation_rate_in_epoch: 1.559661\n",
      "[13000/20794]\n",
      "                loss: 1.225196\n",
      "                current_mean_loss_in_epoch: 1.189492\n",
      "                current_mean_deviation_rate_in_epoch: 1.550117\n",
      "[13500/20794]\n",
      "                loss: 1.232711\n",
      "                current_mean_loss_in_epoch: 1.189415\n",
      "                current_mean_deviation_rate_in_epoch: 1.553052\n",
      "[14000/20794]\n",
      "                loss: 0.770543\n",
      "                current_mean_loss_in_epoch: 1.190059\n",
      "                current_mean_deviation_rate_in_epoch: 1.548185\n",
      "[14500/20794]\n",
      "                loss: 1.078676\n",
      "                current_mean_loss_in_epoch: 1.189686\n",
      "                current_mean_deviation_rate_in_epoch: 1.539070\n",
      "[15000/20794]\n",
      "                loss: 1.214309\n",
      "                current_mean_loss_in_epoch: 1.188365\n",
      "                current_mean_deviation_rate_in_epoch: 1.532554\n",
      "[15500/20794]\n",
      "                loss: 1.547823\n",
      "                current_mean_loss_in_epoch: 1.189994\n",
      "                current_mean_deviation_rate_in_epoch: 1.531928\n",
      "[16000/20794]\n",
      "                loss: 1.491304\n",
      "                current_mean_loss_in_epoch: 1.188984\n",
      "                current_mean_deviation_rate_in_epoch: 1.531124\n",
      "[16500/20794]\n",
      "                loss: 0.689035\n",
      "                current_mean_loss_in_epoch: 1.188302\n",
      "                current_mean_deviation_rate_in_epoch: 1.528915\n",
      "[17000/20794]\n",
      "                loss: 1.038285\n",
      "                current_mean_loss_in_epoch: 1.186536\n",
      "                current_mean_deviation_rate_in_epoch: 1.521470\n",
      "[17500/20794]\n",
      "                loss: 0.736847\n",
      "                current_mean_loss_in_epoch: 1.186563\n",
      "                current_mean_deviation_rate_in_epoch: 1.530171\n",
      "[18000/20794]\n",
      "                loss: 1.223700\n",
      "                current_mean_loss_in_epoch: 1.186024\n",
      "                current_mean_deviation_rate_in_epoch: 1.531337\n",
      "[18500/20794]\n",
      "                loss: 1.119436\n",
      "                current_mean_loss_in_epoch: 1.182524\n",
      "                current_mean_deviation_rate_in_epoch: 1.525689\n",
      "[19000/20794]\n",
      "                loss: 1.608274\n",
      "                current_mean_loss_in_epoch: 1.181521\n",
      "                current_mean_deviation_rate_in_epoch: 1.519962\n",
      "[19500/20794]\n",
      "                loss: 0.767158\n",
      "                current_mean_loss_in_epoch: 1.181288\n",
      "                current_mean_deviation_rate_in_epoch: 1.517348\n",
      "[20000/20794]\n",
      "                loss: 1.816113\n",
      "                current_mean_loss_in_epoch: 1.181136\n",
      "                current_mean_deviation_rate_in_epoch: 1.515206\n",
      "[20500/20794]\n",
      "                loss: 0.279053\n",
      "                current_mean_loss_in_epoch: 1.181972\n",
      "                current_mean_deviation_rate_in_epoch: 1.520884\n",
      "[    0/ 2599]\n",
      "                    loss: 1.134585\n",
      "                    current_mean_loss_in_epoch: 1.134585\n",
      "                    current_mean_deviation_rate_in_epoch: 0.985419\n",
      "[  500/ 2599]\n",
      "                    loss: 1.333549\n",
      "                    current_mean_loss_in_epoch: 1.149294\n",
      "                    current_mean_deviation_rate_in_epoch: 1.519872\n",
      "[ 1000/ 2599]\n",
      "                    loss: 0.658926\n",
      "                    current_mean_loss_in_epoch: 1.153393\n",
      "                    current_mean_deviation_rate_in_epoch: 1.503949\n",
      "[ 1500/ 2599]\n",
      "                    loss: 0.993543\n",
      "                    current_mean_loss_in_epoch: 1.164187\n",
      "                    current_mean_deviation_rate_in_epoch: 1.598614\n",
      "[ 2000/ 2599]\n",
      "                    loss: 0.775132\n",
      "                    current_mean_loss_in_epoch: 1.158412\n",
      "                    current_mean_deviation_rate_in_epoch: 1.629364\n",
      "[ 2500/ 2599]\n",
      "                    loss: 1.122208\n",
      "                    current_mean_loss_in_epoch: 1.158032\n",
      "                    current_mean_deviation_rate_in_epoch: 1.590647\n",
      "Epoch 2\n",
      "---------------------------------------\n",
      "[    0/20794]\n",
      "                loss: 1.276409\n",
      "                current_mean_loss_in_epoch: 1.276409\n",
      "                current_mean_deviation_rate_in_epoch: 0.694439\n",
      "[  500/20794]\n",
      "                loss: 1.487561\n",
      "                current_mean_loss_in_epoch: 1.204863\n",
      "                current_mean_deviation_rate_in_epoch: 1.699972\n",
      "[ 1000/20794]\n",
      "                loss: 1.111201\n",
      "                current_mean_loss_in_epoch: 1.258678\n",
      "                current_mean_deviation_rate_in_epoch: 1.764216\n",
      "[ 1500/20794]\n",
      "                loss: 0.862726\n",
      "                current_mean_loss_in_epoch: 1.220376\n",
      "                current_mean_deviation_rate_in_epoch: 1.658056\n",
      "[ 2000/20794]\n",
      "                loss: 0.451678\n",
      "                current_mean_loss_in_epoch: 1.195317\n",
      "                current_mean_deviation_rate_in_epoch: 1.616978\n",
      "[ 2500/20794]\n",
      "                loss: 1.735470\n",
      "                current_mean_loss_in_epoch: 1.202571\n",
      "                current_mean_deviation_rate_in_epoch: 1.655484\n",
      "[ 3000/20794]\n",
      "                loss: 1.319538\n",
      "                current_mean_loss_in_epoch: 1.199110\n",
      "                current_mean_deviation_rate_in_epoch: 1.635171\n",
      "[ 3500/20794]\n",
      "                loss: 0.709102\n",
      "                current_mean_loss_in_epoch: 1.198244\n",
      "                current_mean_deviation_rate_in_epoch: 1.607527\n",
      "[ 4000/20794]\n",
      "                loss: 1.325100\n",
      "                current_mean_loss_in_epoch: 1.189729\n",
      "                current_mean_deviation_rate_in_epoch: 1.588663\n",
      "[ 4500/20794]\n",
      "                loss: 0.975661\n",
      "                current_mean_loss_in_epoch: 1.188531\n",
      "                current_mean_deviation_rate_in_epoch: 1.557205\n",
      "[ 5000/20794]\n",
      "                loss: 1.147247\n",
      "                current_mean_loss_in_epoch: 1.186714\n",
      "                current_mean_deviation_rate_in_epoch: 1.568073\n",
      "[ 5500/20794]\n",
      "                loss: 1.107766\n",
      "                current_mean_loss_in_epoch: 1.189976\n",
      "                current_mean_deviation_rate_in_epoch: 1.577539\n",
      "[ 6000/20794]\n",
      "                loss: 1.209514\n",
      "                current_mean_loss_in_epoch: 1.187202\n",
      "                current_mean_deviation_rate_in_epoch: 1.570590\n",
      "[ 6500/20794]\n",
      "                loss: 1.006656\n",
      "                current_mean_loss_in_epoch: 1.186361\n",
      "                current_mean_deviation_rate_in_epoch: 1.561672\n",
      "[ 7000/20794]\n",
      "                loss: 1.310411\n",
      "                current_mean_loss_in_epoch: 1.184852\n",
      "                current_mean_deviation_rate_in_epoch: 1.550863\n",
      "[ 7500/20794]\n",
      "                loss: 0.594794\n",
      "                current_mean_loss_in_epoch: 1.184042\n",
      "                current_mean_deviation_rate_in_epoch: 1.551714\n",
      "[ 8000/20794]\n",
      "                loss: 1.239593\n",
      "                current_mean_loss_in_epoch: 1.186057\n",
      "                current_mean_deviation_rate_in_epoch: 1.551109\n",
      "[ 8500/20794]\n",
      "                loss: 0.925533\n",
      "                current_mean_loss_in_epoch: 1.185430\n",
      "                current_mean_deviation_rate_in_epoch: 1.554452\n",
      "[ 9000/20794]\n",
      "                loss: 2.369752\n",
      "                current_mean_loss_in_epoch: 1.186185\n",
      "                current_mean_deviation_rate_in_epoch: 1.549960\n",
      "[ 9500/20794]\n",
      "                loss: 1.508402\n",
      "                current_mean_loss_in_epoch: 1.186326\n",
      "                current_mean_deviation_rate_in_epoch: 1.551956\n",
      "[10000/20794]\n",
      "                loss: 0.841976\n",
      "                current_mean_loss_in_epoch: 1.186298\n",
      "                current_mean_deviation_rate_in_epoch: 1.558747\n",
      "[10500/20794]\n",
      "                loss: 1.007924\n",
      "                current_mean_loss_in_epoch: 1.182796\n",
      "                current_mean_deviation_rate_in_epoch: 1.540371\n",
      "[11000/20794]\n",
      "                loss: 0.829603\n",
      "                current_mean_loss_in_epoch: 1.186658\n",
      "                current_mean_deviation_rate_in_epoch: 1.554048\n",
      "[11500/20794]\n",
      "                loss: 2.267445\n",
      "                current_mean_loss_in_epoch: 1.189181\n",
      "                current_mean_deviation_rate_in_epoch: 1.552400\n",
      "[12000/20794]\n",
      "                loss: 1.049168\n",
      "                current_mean_loss_in_epoch: 1.187558\n",
      "                current_mean_deviation_rate_in_epoch: 1.545540\n",
      "[12500/20794]\n",
      "                loss: 1.941835\n",
      "                current_mean_loss_in_epoch: 1.187906\n",
      "                current_mean_deviation_rate_in_epoch: 1.548432\n",
      "[13000/20794]\n",
      "                loss: 1.227885\n",
      "                current_mean_loss_in_epoch: 1.186882\n",
      "                current_mean_deviation_rate_in_epoch: 1.538999\n",
      "[13500/20794]\n",
      "                loss: 1.231046\n",
      "                current_mean_loss_in_epoch: 1.186843\n",
      "                current_mean_deviation_rate_in_epoch: 1.542398\n",
      "[14000/20794]\n",
      "                loss: 0.776606\n",
      "                current_mean_loss_in_epoch: 1.187458\n",
      "                current_mean_deviation_rate_in_epoch: 1.537777\n",
      "[14500/20794]\n",
      "                loss: 1.076362\n",
      "                current_mean_loss_in_epoch: 1.187125\n",
      "                current_mean_deviation_rate_in_epoch: 1.528552\n",
      "[15000/20794]\n",
      "                loss: 1.176021\n",
      "                current_mean_loss_in_epoch: 1.185839\n",
      "                current_mean_deviation_rate_in_epoch: 1.522516\n",
      "[15500/20794]\n",
      "                loss: 1.525892\n",
      "                current_mean_loss_in_epoch: 1.187524\n",
      "                current_mean_deviation_rate_in_epoch: 1.522057\n",
      "[16000/20794]\n",
      "                loss: 1.491940\n",
      "                current_mean_loss_in_epoch: 1.186556\n",
      "                current_mean_deviation_rate_in_epoch: 1.521359\n",
      "[16500/20794]\n",
      "                loss: 0.694081\n",
      "                current_mean_loss_in_epoch: 1.185872\n",
      "                current_mean_deviation_rate_in_epoch: 1.519048\n",
      "[17000/20794]\n",
      "                loss: 1.042305\n",
      "                current_mean_loss_in_epoch: 1.184149\n",
      "                current_mean_deviation_rate_in_epoch: 1.511911\n",
      "[17500/20794]\n",
      "                loss: 0.708251\n",
      "                current_mean_loss_in_epoch: 1.184214\n",
      "                current_mean_deviation_rate_in_epoch: 1.520896\n",
      "[18000/20794]\n",
      "                loss: 1.227815\n",
      "                current_mean_loss_in_epoch: 1.183692\n",
      "                current_mean_deviation_rate_in_epoch: 1.521848\n",
      "[18500/20794]\n",
      "                loss: 1.101888\n",
      "                current_mean_loss_in_epoch: 1.180164\n",
      "                current_mean_deviation_rate_in_epoch: 1.516063\n",
      "[19000/20794]\n",
      "                loss: 1.588756\n",
      "                current_mean_loss_in_epoch: 1.179183\n",
      "                current_mean_deviation_rate_in_epoch: 1.510300\n",
      "[19500/20794]\n",
      "                loss: 0.740196\n",
      "                current_mean_loss_in_epoch: 1.178908\n",
      "                current_mean_deviation_rate_in_epoch: 1.507395\n",
      "[20000/20794]\n",
      "                loss: 1.805632\n",
      "                current_mean_loss_in_epoch: 1.178805\n",
      "                current_mean_deviation_rate_in_epoch: 1.505351\n",
      "[20500/20794]\n",
      "                loss: 0.270119\n",
      "                current_mean_loss_in_epoch: 1.179679\n",
      "                current_mean_deviation_rate_in_epoch: 1.511525\n",
      "[    0/ 2599]\n",
      "                    loss: 1.139196\n",
      "                    current_mean_loss_in_epoch: 1.139196\n",
      "                    current_mean_deviation_rate_in_epoch: 1.025893\n",
      "[  500/ 2599]\n",
      "                    loss: 1.335627\n",
      "                    current_mean_loss_in_epoch: 1.151055\n",
      "                    current_mean_deviation_rate_in_epoch: 1.564434\n",
      "[ 1000/ 2599]\n",
      "                    loss: 0.672604\n",
      "                    current_mean_loss_in_epoch: 1.154042\n",
      "                    current_mean_deviation_rate_in_epoch: 1.547761\n",
      "[ 1500/ 2599]\n",
      "                    loss: 0.992262\n",
      "                    current_mean_loss_in_epoch: 1.164938\n",
      "                    current_mean_deviation_rate_in_epoch: 1.641973\n",
      "[ 2000/ 2599]\n",
      "                    loss: 0.793299\n",
      "                    current_mean_loss_in_epoch: 1.159440\n",
      "                    current_mean_deviation_rate_in_epoch: 1.677547\n",
      "[ 2500/ 2599]\n",
      "                    loss: 1.139330\n",
      "                    current_mean_loss_in_epoch: 1.159050\n",
      "                    current_mean_deviation_rate_in_epoch: 1.636945\n"
     ]
    }
   ],
   "source": [
    "epochs = 3\n",
    "\n",
    "writer = SummaryWriter()\n",
    "datetime_str = str(datetime.datetime.now()).replace(\" \", \"_\")\n",
    "os.makedirs(\n",
    "    name=f\"checkpoints/{datetime_str}\",\n",
    "    exist_ok=True,\n",
    ")\n",
    "for epoch in range(epochs):\n",
    "    print(f\"Epoch {epoch}\\n---------------------------------------\")\n",
    "    train(\n",
    "        dataloader=train_dl,\n",
    "        model=landnet,\n",
    "        loss_func=loss_func,\n",
    "        optimizer=optimizer,\n",
    "        current_epoch=epoch,\n",
    "        writer=writer,\n",
    "    )\n",
    "    summary_csv_path = os.path.join(\"checkpoints\", datetime_str, f\"landnet_val_epoch{epoch}.csv\")\n",
    "    validate(\n",
    "        dataloader=val_dl,\n",
    "        model=landnet,\n",
    "        loss_func=loss_func,\n",
    "        current_epoch=epoch,\n",
    "        writer=writer,\n",
    "        summary_csv_path=summary_csv_path\n",
    "    )\n",
    "    torch.save(\n",
    "        obj=landnet.state_dict(),\n",
    "        f=os.path.join(\"checkpoints\", datetime_str, f\"landnet_checkpoint_epoch{epoch}.pth\")\n",
    "    )\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    0/ 2600]\n",
      "                    loss: 0.977846\n",
      "                    current_mean_loss_in_epoch: 0.977846\n",
      "                    current_mean_deviation_rate_in_epoch: 1.105529\n",
      "[  500/ 2600]\n",
      "                    loss: 1.444187\n",
      "                    current_mean_loss_in_epoch: 1.231535\n",
      "                    current_mean_deviation_rate_in_epoch: 1.695905\n",
      "[ 1000/ 2600]\n",
      "                    loss: 1.411825\n",
      "                    current_mean_loss_in_epoch: 1.189711\n",
      "                    current_mean_deviation_rate_in_epoch: 1.513361\n",
      "[ 1500/ 2600]\n",
      "                    loss: 1.721498\n",
      "                    current_mean_loss_in_epoch: 1.213530\n",
      "                    current_mean_deviation_rate_in_epoch: 1.575023\n",
      "[ 2000/ 2600]\n",
      "                    loss: 1.143088\n",
      "                    current_mean_loss_in_epoch: 1.202851\n",
      "                    current_mean_deviation_rate_in_epoch: 1.518699\n",
      "[ 2500/ 2600]\n",
      "                    loss: 0.975257\n",
      "                    current_mean_loss_in_epoch: 1.215291\n",
      "                    current_mean_deviation_rate_in_epoch: 1.552785\n"
     ]
    }
   ],
   "source": [
    "validate(\n",
    "    dataloader=test_dl,\n",
    "    model=landnet,\n",
    "    loss_func=loss_func,\n",
    "    current_epoch=0,\n",
    "    summary_csv_path=os.path.join(\"checkpoints\", datetime_str, \"landnet_test.csv\"),\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
